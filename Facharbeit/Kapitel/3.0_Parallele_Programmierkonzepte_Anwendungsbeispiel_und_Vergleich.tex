% Abschlussarbeit am Ende der Oberschule
% Facharbeit zum parallelen Programmierparadigma
% Thomas Mittermair
% Oberschulzentrum J. Ph. Fallmerayer Brixen

\chapter{Parallele Programmierkonzepte, Anwendungsbeispiel und Vergleich}

	\section{Parallele Programmierkonzepte}
	
		Seit der Entwicklung des parallelen Programmierparadigmas haben sich einige Konzepte und vor allem Programmiersprachen-Bibliotheken herausgebildet, wovon drei heute noch eingesetzte in diesem Kapitel erläutert werden sollen. Danach werden diese drei Technologie untereinander und auch mit reinen Prozessen und Threads anhand eines Anwendungsbeispiels verglichen.
		
		\subsection{MPI (Message Passing Interface)}
			\label{MPI}

			MPI, das \textit{Message Passing Interface}, wendet wie sich vom Namen bereits ableiten lässt das Message-Passing-Modell an. Dieses Modell geht davon aus, dass ein Parallelrechner mit verteiltem Speicher vorliegt, wobei jeder Prozess einen eigenen, lokalen Speicher besitzt. Da kein globaler Speicher in diesem Modell existiert, muss die Kommunikation zwischen den Prozessoren durch den Austausch von Nachrichten (Message-Passing) erfolgen. Um Daten vom lokalen Speicher eines Prozessors A in den eines anderen Prozessors B zu übertragen, muss A eine Nachricht an B senden, welche die Daten enthält. B muss die Nachricht dann empfangen und die Daten in einen Puffer, welcher im lokalen Speicher gespeichert wird, abspeichern.\\
			Um die Portabilität zu gewährleisten, werden keine Annahmen in Bezug auf das Verbindungsnetzwerk zwischen den Prozessoren gemacht. Jeder Prozessor kann mit jedem anderen Prozessor kommunizieren.\\
			Ein Programm, welches Message Passing verwendet, wird von einer Reihe von Prozessen ausgeführt, wobei jeder Prozess einen lokalen Speicher zur Verfügung hat und (im Optimalfall) auf einem eigenen Prozessor bzw. Prozessor-Kern läuft. Die Anzahl der beteiligten Prozesse wird meist beim Programmstart festgelegt. Jeder Prozess kann nun, analog zur zuvor erläuterten Funktionsweise, mit den lokalen Daten direkt arbeiten und mit den anderen Prozessen über das Senden und Empfangen von Nachrichten kommunizieren. Jeder Prozess kann dabei die selbe, aber auch verschiedene Aufgaben erfüllen.\\
			Den einzelnen Prozessen, die das Message-Passing-Programmm ausführen, müssen Kommunikationsoperationen zum Realisieren des Message-Passings zur Verfügung gestellt werden. Dies geschieht in der Regel durch eine Bibliothek einer Programmiersprache. Die Prozesse können dann auf die Funktionen, welche die Bibliothek bereitstellt, zugreifen.\\
			Eine solche Kommunikations-Bibliothek ist in der Regel hardwareunabhängig, weshalb sie auf verschiedensten Parallelrechnern genutzt werden können. Die bekannteste dieser Bibliotheken ist das MPI (\textit{Message Passing Interface}).\\
			MPI ist ein Standard zur Realisierung des Message-Passing-Modells. Es definiert die Syntax und Semantik von Funktionen, welche die Kommunikation und somit den Daten-Austausch ermöglichen. Die genaue Implementierung wird allerdings durch den Standard nicht festgelegt. Frei verfügbare Implementierungen sind beispielsweise MPICH, LAM/MPI oder auch OpenMPI (nicht zu verwechseln mit OpenMP, welches unter Kapitel \ref{OpenMP} erläutert wird).\\
			Diese Bibliothek wird für C, C++ und Fortran unterstützt. Der momentan aktuellste Standard ist MPI-3, welches 2012 erschienen ist. \cite{ParaProgRauber}
			
		\subsection{OpenMP (Open Multi-Processing)}
			\label{OpenMP}
			
			Der Standard OpenMP (\textit{Open Multi-Processing}) verfolgt einen etwas anderen Ansatz als MPI, da selbiger für Parallelrechner mit gemeinsamem Speicher ausgelegt ist. Die OpenMP-API\footnote{Eine API (\textit{Application Programming Interface}) ist eine Programmierschnittstelle, das heißt ein Programmteil, der anderen Programmen zur Anbindung an das System zur Verfügung gestellt wird. \cite{APIWikipedia}} stellt dabei eine Reihe von Compiler-Direktiven, Funktionen und Variablen zur Verfügung. Mit Hilfe dieser Compiler-Direktiven können die für gewöhnlich sequentiellen Programmiersprachen C, C++ und Fortran um Konstrukte zur parallelen Programmierung und auch zur Synchronisierung erweitert werden. Dabei kann sowohl lokaler, als auch gemeinsamer Speicher genutzt werden.\\
			Der erste OpenMP-Standard wurde im Jahre 1997 veröffentlicht und die Version 2.5 aus dem Jahr 2005 wird mittlerweile von den meisten Compilern unterstützt.\\
			Das Programmiermodell von OpenMP entspricht im Gegensatz zu dem von MPI auf zusammenarbeitenden Threads, welche parallel wiederum auf Prozessoren bzw. Prozessor-Kernen laufen. Die Erzeugung und Beendigung der Threads folgt dem unter Kapitel \ref{ForkJoinModell} vorgestellten Fork-Join-Modell. Wird ein OpenMP-Programm ausgeführt, so existiert zunächst nur genau ein Thread, welche \textit{Intial Thread} genannt wird. Somit erfolgt die Abarbeitung des Programmes sequentiell, bis das erste OpenMP-Konstrukt zur Parallelisierung gefunden wird. In diesem Schritt erzeugt der \textit{Intial Thread} eine Reihe von neuen Threads und bildet zusammen mit den neuen Threads ein Team, wobei der \textit{Intial Thread} zum \textit{Master Thread} befördert wird. Die Fork-Operation wird implizit durchgeführt, wird also vom Programmierer nicht direkt in die Wege geleitet. Der Programmcode innerhalb des parallelen Konstruktes wird \textit{parallele Region} genannt und wird vom gesamten Thread-Team ausgeführt. Jeder Thread kann dabei die selbe, aber auch verschiedene Aufgaben erfüllen. Am Ende der parallelen Region findet sich eine implizite Synchronisation und nur der Master Thread führt dann die Ausführung weiter, was einer impliziten Join-Operation entspricht. Parallele Regionen können auch verschachtelt werden, wobei jeder Thread, der auf ein OpenMP-Konstrukt zur Parallelisierung trifft, ein Team von Threads bildet und selbst zu einem \textit{Master Thread} wird.\\
			Das Speicher-Modell von OpenMP unterscheidet zwischen lokalem und gemeinsamem Speicher, wobei alle OpenMP-Threads auf den letztgenannten Speicher Zugriff haben. Um die unter Kapitel \ref{ProblemeParalleleBearbeitung} vorgestellten Probleme der Synchronisation wie beispielsweise zeitkritische Abläufe oder auch Deadlocks zu vermeiden, stellt der OpenMP-Standard auch Synchronisationsmechanismen in Form von Bibliotheksfunktionen zur Verfügung. Zusätzlich zu gemeinsame genutzten Variablen können die Threads auch private Variablen verwenden, welche nicht von anderen Threads zugegriffen werden können.\\
			Die Kompilierung eines OpenMP-Programmes führt zu einem Code, welcher Multithreading verwendet. \cite{ParaProgRauber} \cite{OpenMPWikipedia}
			
		\subsection{Cilk}
			\label{Cilk}
		
			Cilk, Cilk++ und Cilk Plus sind im Gegensatz zu MPI und OpenMP keine Standards, sondern eigene Programmiersprachen, welche für paralleles Rechnen unter Verwendung von Multithreading optimiert wurden. Die Syntax und Semantik ist an C und C++ angelehnt, weshalb diese Programmiersprachen als Erweiterungen von C bzw. C++ betrachtet werden können, welche das Parallelisieren von Schleifen und das Fork-Join-Modell, welche unter Kapitel \ref{ForkJoinModell} erläutert wurde, unterstützen.\\
			Die Programmiersprache Cilk wurde vom \textit{MIT Laboratory for Computer Science} entwickelt und 1994 veröffentlicht. Der Name \textit{Cilk} ist dabei eine Anspielung an Threads, welche Ausführungsfäden darstellen. Das englische Wort \textit{Silk}, welches mit \textit{(Seiden-) Faden} übersetzt werden kann, wurde so verändert, dass aus dem \textit{S} ein \textit{C} wurde, um auf die Programmiersprache C, auf welcher Cilk basiert, zu verweisen.\\
			Vor 2006 war Cilk nur auf Hochleistungsrechnen im professionellen Stil beschränkt und somit nicht verbreitet. Aus diesem Grund wurde das Unternehmen \textit{Cilk Arts} gegründet, welches die Programmiersprache Cilk modernisierte und somit kommerziell nutzbar machte. Die neue Version von Cilk wurde \textit{Cilk++} genannt und erschient 2008. Der Zusatz \textit{++} rührt daher, dass von nun an auch C++ unterstützt wurde.\\
			2009 gab Cilk Arts bekannt, von nun an Teil der \textit{Intel Corporation} zu sein. Bald darauf wurde Cilk++ zur aktuellen Version \textit{Intel Cilk Plus} erweitert. Selbige erschien im Jahre 2010.\\
			Das Konzept hinter Cilk besteht darin, dass der Programmierer dafür zuständig sein sollte, die Abschnitte im Code, die parallel verarbeitet werden können, zu identifizieren und mit den korrekten \textit{Cilk}-Schlüsselwörtern zu markieren. Er muss dann allerdings der Laufzeitumgebung die Aufgabe überlassen, wie die Arbeit genau auf die verfügbaren Prozessoren mit Hilfe von Threads aufgeteilt wird. Genau aus diesem Grund ist ein und dasselbe Cilk-Programm auf einem Ein-, aber auch auf einem \textit{n}-Prozessor-System lauffähig, ohne Veränderungen im Quellcode tätigen zu müssen.\\
			Im Folgenden werden die wichtigsten beiden Schlüsselwörter, um die Cilk Plus die Programmiersprache C erweitert, erläutert. Dabei handelt es sich um die beiden Wörter \textit{spawn} (zu Deutsch \textit{vermehren}), und \textit{sync} (in Anlehnung an \textit{Synchronisierung}). Beide werden in Zusammenhang mit der Realisierung des unter Kapitel \ref{ForkJoinModell} erwähnten Fork-Join-Modell benötigt. Das \textit{spawn}-Schlüsselwort wird einem Funktionsaufruf vorangestellt (beispielsweise \textit{spawn f(x)}). Das bedeutet, dass die Anweisungen innerhalb der Funktion \textit{f(x)} problemlos parallel zu den auf den Funktionsaufruf folgenden Anweisungen ausgeführt werden kann. Der Scheduler ist allerdings nicht gezwungen, diesen Code dann tatsächlich parallel auszuführen. Dieses Schlüsselwort kann also eher als eine \textit{Empfehlung der parallelen Verarbeitung} betrachtet werden. Dieses Schlüsselwort realisiert also einen Fork. Das \textit{sync}-Schlüsselwort ist das Gegenstück zu \textit{spawn}. Es weist den Compiler darauf hin, dass die Ausführung der darauf folgenden Anweisungen erst vollzogen werden kann, sobald alle zuvor mit Hilfe des Schlüsselworts \textit{spawn} parallel ausgeführten Funktionen vollständig abgearbeitet worden sind. Somit wird durch dieses Schlüsselwort ein Join realisiert. \cite{CilkWikipedia}
		
	\section{Anwendungsbeispiel und Vergleich der parallelen Programmierkonzepte}
	
		HIER BIN ICH.